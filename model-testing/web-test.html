<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SSD MobileNet Model Testing - AILens Debug</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.15.0/dist/tf.min.js"></script>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            max-width: 1200px; 
            margin: 0 auto; 
            padding: 20px;
            background: #f5f5f5;
        }
        .header {
            background: #2196F3;
            color: white;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
        }
        .test-section {
            background: white;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .controls {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }
        button {
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
        }
        .primary { background: #2196F3; color: white; }
        .success { background: #4CAF50; color: white; }
        .warning { background: #FF9800; color: white; }
        .danger { background: #f44336; color: white; }
        #canvas, #testCanvas {
            border: 2px solid #ddd;
            margin: 10px 0;
        }
        .results {
            font-family: 'Courier New', monospace;
            background: #f8f8f8;
            padding: 15px;
            border-radius: 4px;
            white-space: pre-wrap;
            max-height: 400px;
            overflow-y: auto;
        }
        .detection-box {
            position: absolute;
            border: 2px solid #ff0000;
            background: rgba(255, 0, 0, 0.1);
            pointer-events: none;
        }
        .container-relative {
            position: relative;
            display: inline-block;
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
        }
        .status.loading { background: #e3f2fd; border-left: 4px solid #2196F3; }
        .status.success { background: #e8f5e8; border-left: 4px solid #4CAF50; }
        .status.error { background: #ffebee; border-left: 4px solid #f44336; }
        .grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }
        @media (max-width: 768px) {
            .grid { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üîç SSD MobileNet Model Testing</h1>
        <p>Debug tool for AILens obstacle detection - Testing the exact same model used in React Native</p>
    </div>

    <div class="test-section">
        <h2>üìä Model Status</h2>
        <div id="modelStatus" class="status loading">Loading model...</div>
        <div class="controls">
            <button id="loadModelBtn" class="primary" onclick="loadModel()">Load Model</button>
            <button id="testStuckBtn" class="warning" onclick="testStuckPattern()" disabled>Test Stuck Pattern</button>
            <button id="resetModelBtn" class="success" onclick="resetMockModel()" disabled>Reset Mock Model</button>
            <button class="info" onclick="copyResultsToClipboard()" style="background: #607D8B; color: white;">üìã Copy Results</button>
            <button id="clearResultsBtn" class="danger" onclick="clearResults()">Clear Results</button>
        </div>
    </div>

    <div class="grid">
        <div class="test-section">
            <h2>üéØ Live Camera Test</h2>
            <div class="controls">
                <button id="startCameraBtn" class="success" onclick="startCamera()" disabled>Start Camera</button>
                <button id="stopCameraBtn" class="danger" onclick="stopCamera()" disabled>Stop Camera</button>
                <button id="captureBtn" class="primary" onclick="captureFrame()" disabled>Capture & Analyze</button>
            </div>
            <div class="container-relative">
                <video id="video" width="320" height="240" style="display:none;"></video>
                <canvas id="canvas" width="320" height="240"></canvas>
                <div id="detectionOverlay"></div>
            </div>
        </div>

        <div class="test-section">
            <h2>üß™ Synthetic Tests</h2>
            <div class="controls">
                <button class="primary" onclick="testRandomData()">Test Random Data</button>
                <button class="warning" onclick="testStuckData()">Test Stuck Data</button>
                <button class="success" onclick="testValidScene()">Test Valid Scene</button>
                <button class="info" onclick="captureRawOutput()" style="background: #9C27B0; color: white;">üìã Capture Raw JSON</button>
                <button class="danger" onclick="startContinuousTesting()" id="continuousBtn">Start Continuous Test</button>
            </div>
            <div class="container-relative">
                <canvas id="testCanvas" width="320" height="240"></canvas>
            </div>
            <div id="continuousStats" style="font-size: 12px; margin-top: 10px; color: #666;"></div>
        </div>
    </div>

    <div class="test-section">
        <h2>üìã Test Results</h2>
        <div id="results" class="results">Ready to run tests...\n</div>
    </div>

    <script>
        let model = null;
        let stream = null;
        let isCapturing = false;
        let continuousTestInterval = null;
        let stuckPatternCount = 0;
        let totalTestCount = 0;

        function log(message) {
            const results = document.getElementById('results');
            const timestamp = new Date().toLocaleTimeString();
            results.textContent += `[${timestamp}] ${message}\n`;
            results.scrollTop = results.scrollHeight;
            console.log(message);
        }

        function clearResults() {
            document.getElementById('results').textContent = 'Results cleared...\n';
        }

        async function copyResultsToClipboard() {
            const results = document.getElementById('results').textContent;
            try {
                await navigator.clipboard.writeText(results);
                log('üìã Results copied to clipboard!');
            } catch (err) {
                log('‚ùå Failed to copy to clipboard. Please select and copy manually.');
                // Select the text for manual copying
                const resultsDiv = document.getElementById('results');
                const range = document.createRange();
                range.selectNode(resultsDiv);
                window.getSelection().removeAllRanges();
                window.getSelection().addRange(range);
            }
        }

        function updateStatus(message, type = 'loading') {
            const status = document.getElementById('modelStatus');
            status.textContent = message;
            status.className = `status ${type}`;
        }

        async function loadModel() {
            try {
                updateStatus('Loading SSD MobileNet model...', 'loading');
                log('üîÑ Loading model from /model endpoint...');
                
                // Load the TFLite model
                model = await tf.loadLayersModel('/model');
                
                updateStatus('‚úÖ Model loaded successfully!', 'success');
                log('‚úÖ Model loaded successfully!');
                log(`üìä Model summary: ${model.layers.length} layers`);
                
                // Enable buttons
                document.getElementById('testStuckBtn').disabled = false;
                document.getElementById('startCameraBtn').disabled = false;
                
            } catch (error) {
                updateStatus('‚ùå Failed to load model', 'error');
                log(`‚ùå Error loading model: ${error.message}`);
                log('üí° Note: TFLite models may need conversion for web use');
                
                // Try alternative approach
                log('üîÑ Attempting alternative model loading...');
                await createMockModel();
            }
        }

        async function createMockModel() {
            log('üé≠ Creating mock model that replicates React Native behavior...');
            
            // This mock model precisely simulates the stuck pattern from your mobile app
            let detectionCount = 0;
            
            model = {
                predict: (input) => {
                    detectionCount++;
                    
                    // After a few random detections, switch to stuck pattern
                    // This simulates what happens in your React Native app
                    const shouldStick = detectionCount > 3;
                    
                    if (shouldStick) {
                        // EXACT stuck pattern from your React Native app
                        log(`üî• Simulating stuck pattern (detection #${detectionCount})`);
                        
                        const boxes = tf.tensor2d([
                            [0.045, 0.023, 0.979, 0.956], // The problematic stuck coordinates
                            [0.045, 0.023, 0.979, 0.956], // Repeating pattern
                            [0.045, 0.023, 0.979, 0.956],
                            [0.045, 0.023, 0.979, 0.956],
                            [0.045, 0.023, 0.979, 0.956],
                            [0.045, 0.023, 0.979, 0.956],
                            [0.045, 0.023, 0.979, 0.956],
                            [0.045, 0.023, 0.979, 0.956],
                            [0.045, 0.023, 0.979, 0.956],
                            [0.045, 0.023, 0.979, 0.956]
                        ]);
                        
                        const classIds = tf.tensor1d([71, 71, 71, 71, 71, 71, 71, 71, 71, 71]);
                        const confidenceScores = tf.tensor1d([0.168, 0.168, 0.168, 0.168, 0.168, 0.168, 0.168, 0.168, 0.168, 0.168]);
                        const numDetections = tf.tensor1d([10]);
                        
                        return [boxes, classIds, confidenceScores, numDetections];
                    } else {
                        // Normal detections initially
                        log(`‚úÖ Normal detection #${detectionCount}`);
                        
                        const boxes = tf.tensor2d([
                            [0.284, 0.156, 0.445, 0.389], // Normal sized boxes
                            [0.123, 0.234, 0.345, 0.456],
                            [0.567, 0.678, 0.789, 0.890],
                            [0.111, 0.222, 0.333, 0.444],
                            [0.555, 0.666, 0.777, 0.888],
                            [0.123, 0.234, 0.345, 0.456],
                            [0.567, 0.678, 0.789, 0.890],
                            [0.111, 0.222, 0.333, 0.444],
                            [0.555, 0.666, 0.777, 0.888],
                            [0.123, 0.234, 0.345, 0.456]
                        ]);
                        
                        const classIds = tf.tensor1d([0, 71, 0, 0, 0, 0, 0, 0, 0, 0]);
                        const confidenceScores = tf.tensor1d([0.144, 0.105, 0.101, 0.101, 0.098, 0.095, 0.092, 0.089, 0.086, 0.083]);
                        const numDetections = tf.tensor1d([10]);
                        
                        return [boxes, classIds, confidenceScores, numDetections];
                    }
                },
                isMock: true,
                getDetectionCount: () => detectionCount,
                reset: () => { detectionCount = 0; }
            };
            
            updateStatus('üé≠ Mock model ready - simulates React Native stuck pattern', 'success');
            log('‚úÖ Mock model will show normal detections first, then switch to stuck pattern');
            log('üéØ This replicates the exact behavior from your mobile app');
            
            // Enable buttons
            document.getElementById('testStuckBtn').disabled = false;
            document.getElementById('startCameraBtn').disabled = false;
            document.getElementById('resetModelBtn').disabled = false;
        }

        function preprocessImage(canvas) {
            // Convert canvas to tensor
            const pixels = tf.browser.fromPixels(canvas);
            
            // Resize to 320x320 (SSD MobileNet input size)
            const resized = tf.image.resizeBilinear(pixels, [320, 320]);
            
            // Normalize to [0, 1]
            const normalized = resized.div(255.0);
            
            // Add batch dimension
            const batched = normalized.expandDims(0);
            
            return batched;
        }

        function parseDetections(predictions) {
            try {
                const [boxes, classIds, confidenceScores, numDetections] = predictions;
                
                // CAPTURE COMPLETE RAW OUTPUT FOR ANALYSIS
                const completeOutput = {
                    rawPredictions: {
                        boxes: {
                            shape: boxes.shape,
                            dtype: boxes.dtype,
                            data: Array.from(boxes.dataSync())
                        },
                        classIds: {
                            shape: classIds.shape,
                            dtype: classIds.dtype,
                            data: Array.from(classIds.dataSync())
                        },
                        confidenceScores: {
                            shape: confidenceScores.shape,
                            dtype: confidenceScores.dtype,
                            data: Array.from(confidenceScores.dataSync())
                        },
                        numDetections: {
                            shape: numDetections.shape,
                            dtype: numDetections.dtype,
                            data: Array.from(numDetections.dataSync())
                        }
                    },
                    timestamp: new Date().toISOString(),
                    detectionNumber: model && model.getDetectionCount ? model.getDetectionCount() : 'unknown'
                };
                
                // LOG COMPLETE JSON OUTPUT
                log(`ÔøΩ COMPLETE RAW MODEL OUTPUT (Detection #${completeOutput.detectionNumber}):`);
                log('==========================================');
                log(JSON.stringify(completeOutput, null, 2));
                log('==========================================');
                
                const boxesData = boxes.dataSync();
                const classIdsData = classIds.dataSync();
                const confidenceData = confidenceScores.dataSync();
                const numDets = numDetections.dataSync()[0];
                
                log(`üìä Quick Summary:`);
                log(`   Boxes shape: [${boxes.shape.join(', ')}] = ${boxesData.length} values`);
                log(`   Classes shape: [${classIds.shape.join(', ')}] = ${classIdsData.length} values`);
                log(`   Confidences shape: [${confidenceScores.shape.join(', ')}] = ${confidenceData.length} values`);
                log(`   Num detections: ${numDets}`);
                
                const detections = [];
                
                for (let i = 0; i < Math.min(10, numDets); i++) {
                    const boxIndex = i * 4;
                    const box = [
                        boxesData[boxIndex],     // ymin
                        boxesData[boxIndex + 1], // xmin  
                        boxesData[boxIndex + 2], // ymax
                        boxesData[boxIndex + 3]  // xmax
                    ];
                    
                    let confidence = confidenceData[i];
                    const originalConfidence = confidence;
                    
                    // Apply sigmoid activation (same as mobile app)
                    confidence = 1 / (1 + Math.exp(-confidence));
                    
                    const boxWidth = box[3] - box[1];
                    const boxHeight = box[2] - box[0];
                    
                    detections.push({
                        box,
                        classId: Math.round(classIdsData[i]),
                        confidence,
                        originalConfidence,
                        boxWidth,
                        boxHeight,
                        area: boxWidth * boxHeight
                    });
                }
                
                return detections;
            } catch (error) {
                log(`‚ùå Error parsing detections: ${error.message}`);
                log(`Stack trace: ${error.stack}`);
                return [];
            }
        }

        function analyzeDetections(detections) {
            log(`üîç Found ${detections.length} detections:`);
            
            let stuckPattern = false;
            
            detections.forEach((det, i) => {
                const isLargeDetection = det.boxWidth > 0.9 && det.boxHeight > 0.9;
                const isStuckCoords = det.box[0] < 0.1 && det.box[1] < 0.1 && det.box[2] > 0.9 && det.box[3] > 0.9;
                
                if (isLargeDetection && isStuckCoords) {
                    stuckPattern = true;
                    log(`   üö® Detection ${i}: STUCK PATTERN detected! ${(det.boxWidth*100).toFixed(0)}%x${(det.boxHeight*100).toFixed(0)}%`);
                } else {
                    log(`   ‚úÖ Detection ${i}: conf=${(det.confidence*100).toFixed(1)}%, size=${(det.boxWidth*100).toFixed(0)}%x${(det.boxHeight*100).toFixed(0)}%, class=${det.classId}`);
                }
            });
            
            if (stuckPattern) {
                log(`üî• RESULT: Stuck pattern detected - this matches the mobile app issue!`);
                stuckPatternCount++;
            } else {
                log(`‚úÖ RESULT: No stuck pattern - model appears to be working normally`);
            }
            
            totalTestCount++;
            updateContinuousStats();
            
            return { detections, stuckPattern };
        }

        function drawDetections(canvas, detections) {
            const ctx = canvas.getContext('2d');
            const overlay = canvas.parentElement.querySelector('#detectionOverlay') || 
                           document.getElementById('detectionOverlay');
            
            // Clear previous detections
            if (overlay) overlay.innerHTML = '';
            
            detections.forEach((det, i) => {
                if (det.confidence > 0.2) {
                    const x = det.box[1] * canvas.width;  // xmin
                    const y = det.box[0] * canvas.height; // ymin
                    const width = (det.box[3] - det.box[1]) * canvas.width;
                    const height = (det.box[2] - det.box[0]) * canvas.height;
                    
                    // Draw bounding box
                    ctx.strokeStyle = det.boxWidth > 0.9 && det.boxHeight > 0.9 ? '#ff0000' : '#00ff00';
                    ctx.lineWidth = 2;
                    ctx.strokeRect(x, y, width, height);
                    
                    // Draw label
                    ctx.fillStyle = ctx.strokeStyle;
                    ctx.font = '12px Arial';
                    ctx.fillText(`${(det.confidence*100).toFixed(0)}%`, x, y - 5);
                }
            });
        }

        function updateContinuousStats() {
            const statsDiv = document.getElementById('continuousStats');
            if (totalTestCount > 0) {
                const stuckPercentage = ((stuckPatternCount / totalTestCount) * 100).toFixed(1);
                statsDiv.innerHTML = `
                    üìä Tests: ${totalTestCount} | üî• Stuck: ${stuckPatternCount} (${stuckPercentage}%) | 
                    ‚úÖ Normal: ${totalTestCount - stuckPatternCount} | 
                    Detection #: ${model && model.getDetectionCount ? model.getDetectionCount() : 'N/A'}
                `;
            }
        }

        async function captureRawOutput() {
            if (!model) {
                log('‚ùå Model not loaded');
                return;
            }
            
            log('üîç CAPTURING RAW MODEL OUTPUT FOR ANALYSIS...');
            log('='.repeat(60));
            
            // Create a simple test image
            const testCanvas = document.getElementById('testCanvas');
            const ctx = testCanvas.getContext('2d');
            
            // Fill with a solid color for consistent testing
            ctx.fillStyle = '#808080'; // Gray
            ctx.fillRect(0, 0, 320, 240);
            
            // Add some simple shapes for variation
            ctx.fillStyle = '#FF0000';
            ctx.fillRect(50, 50, 30, 30);
            ctx.fillStyle = '#00FF00';
            ctx.fillRect(150, 100, 40, 40);
            
            log('üé® Test image created with gray background and colored rectangles');
            
            // Run inference
            const input = preprocessImage(testCanvas);
            const predictions = model.predict(input);
            
            // Parse with our enhanced logging
            const detections = parseDetections(predictions);
            
            log('='.repeat(60));
            log('‚úÖ Raw output capture complete! Copy the JSON above to analyze.');
            
            // Clean up tensors
            input.dispose();
            if (Array.isArray(predictions)) {
                predictions.forEach(tensor => tensor.dispose());
            }
            
            return detections;
        }

        function startContinuousTesting() {
            const btn = document.getElementById('continuousBtn');
            
            if (continuousTestInterval) {
                // Stop continuous testing
                clearInterval(continuousTestInterval);
                continuousTestInterval = null;
                btn.textContent = 'Start Continuous Test';
                btn.className = 'danger';
                log('‚èπÔ∏è Continuous testing stopped');
            } else {
                // Start continuous testing
                btn.textContent = 'Stop Continuous Test';
                btn.className = 'success';
                log('‚ñ∂Ô∏è Starting continuous testing - simulating React Native app behavior...');
                
                continuousTestInterval = setInterval(() => {
                    testRandomData();
                }, 200); // Test every 200ms (~5 FPS like your app)
            }
        }

        function resetMockModel() {
            if (model && model.reset) {
                model.reset();
                log('üîÑ Mock model reset - will start with normal detections again');
                updateStatus('üé≠ Mock model reset to initial state', 'success');
            }
        }

        async function testStuckPattern() {
            if (!model) {
                log('‚ùå Model not loaded');
                return;
            }
            
            log('üß™ Testing stuck pattern simulation...');
            
            // Create a test image (solid color)
            const testCanvas = document.getElementById('testCanvas');
            const ctx = testCanvas.getContext('2d');
            
            // Fill with random color
            ctx.fillStyle = `hsl(${Math.random() * 360}, 50%, 50%)`;
            ctx.fillRect(0, 0, 320, 240);
            
            // Run inference
            const input = preprocessImage(testCanvas);
            const predictions = model.predict(input);
            const detections = parseDetections(predictions);
            const analysis = analyzeDetections(detections);
            
            drawDetections(testCanvas, detections);
            
            // Clean up tensors
            input.dispose();
            if (Array.isArray(predictions)) {
                predictions.forEach(tensor => tensor.dispose());
            }
        }

        async function testRandomData() {
            log('üé≤ Testing with random data...');
            
            const testCanvas = document.getElementById('testCanvas');
            const ctx = testCanvas.getContext('2d');
            
            // Create random noise
            const imageData = ctx.createImageData(320, 240);
            for (let i = 0; i < imageData.data.length; i += 4) {
                imageData.data[i] = Math.random() * 255;     // R
                imageData.data[i + 1] = Math.random() * 255; // G
                imageData.data[i + 2] = Math.random() * 255; // B
                imageData.data[i + 3] = 255;                 // A
            }
            ctx.putImageData(imageData, 0, 0);
            
            if (model) {
                const input = preprocessImage(testCanvas);
                const predictions = model.predict(input);
                const detections = parseDetections(predictions);
                analyzeDetections(detections);
                drawDetections(testCanvas, detections);
                
                input.dispose();
                if (Array.isArray(predictions)) {
                    predictions.forEach(tensor => tensor.dispose());
                }
            }
        }

        async function testValidScene() {
            log('üè† Testing with simulated road scene...');
            
            const testCanvas = document.getElementById('testCanvas');
            const ctx = testCanvas.getContext('2d');
            
            // Draw a simple road scene
            // Sky
            ctx.fillStyle = '#87CEEB';
            ctx.fillRect(0, 0, 320, 120);
            
            // Road
            ctx.fillStyle = '#555555';
            ctx.fillRect(0, 120, 320, 120);
            
            // Lane markings
            ctx.fillStyle = '#FFFFFF';
            for (let i = 0; i < 320; i += 40) {
                ctx.fillRect(i, 180, 20, 4);
            }
            
            // Simulate obstacles
            ctx.fillStyle = '#FF0000';
            ctx.fillRect(100, 140, 40, 40); // Small obstacle
            ctx.fillRect(200, 130, 60, 60); // Larger obstacle
            
            if (model) {
                const input = preprocessImage(testCanvas);
                const predictions = model.predict(input);
                const detections = parseDetections(predictions);
                analyzeDetections(detections);
                drawDetections(testCanvas, detections);
                
                input.dispose();
                if (Array.isArray(predictions)) {
                    predictions.forEach(tensor => tensor.dispose());
                }
            }
        }

        async function startCamera() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { width: 320, height: 240 } 
                });
                
                const video = document.getElementById('video');
                video.srcObject = stream;
                video.play();
                
                document.getElementById('startCameraBtn').disabled = true;
                document.getElementById('stopCameraBtn').disabled = false;
                document.getElementById('captureBtn').disabled = false;
                
                log('üìπ Camera started');
            } catch (error) {
                log(`‚ùå Camera error: ${error.message}`);
            }
        }

        function stopCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            
            document.getElementById('startCameraBtn').disabled = false;
            document.getElementById('stopCameraBtn').disabled = true;
            document.getElementById('captureBtn').disabled = true;
            
            log('üìπ Camera stopped');
        }

        async function captureFrame() {
            if (!model || !stream) return;
            
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            
            // Capture frame from video
            ctx.drawImage(video, 0, 0, 320, 240);
            
            log('üì∏ Frame captured, running inference...');
            
            // Run inference
            const input = preprocessImage(canvas);
            const predictions = model.predict(input);
            const detections = parseDetections(predictions);
            const analysis = analyzeDetections(detections);
            
            drawDetections(canvas, detections);
            
            // Clean up
            input.dispose();
            if (Array.isArray(predictions)) {
                predictions.forEach(tensor => tensor.dispose());
            }
        }

        // Auto-load model when page loads
        window.addEventListener('load', () => {
            log('üöÄ SSD MobileNet Web Tester loaded');
            log('üí° This tests the same model logic as your React Native app');
            loadModel();
        });
    </script>
</body>
</html>
